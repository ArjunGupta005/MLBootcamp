{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv9iHpm5yYy9",
        "outputId": "81105a91-fd84-45f3-b96b-7313c8c0bb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 00:07:15--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.210.207, 173.194.216.207, 173.194.217.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.210.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   145MB/s    in 0.5s    \n",
            "\n",
            "2024-11-07 00:07:16 (145 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9jfbCPDyi4E"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Initialize empty lists before the loop\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# Define the target size for your images\n",
        "target_size = (64, 64)  # Common size for ML models, adjust as needed\n",
        "\n",
        "cats_dir = os.path.join(train_dir + \"/cats\")\n",
        "dogs_dir = os.path.join(train_dir + \"/dogs\")\n",
        "\n",
        "# Get list of files first\n",
        "cats_files = os.listdir(cats_dir)\n",
        "dogs_files = os.listdir(dogs_dir)\n",
        "\n",
        "i = 0\n",
        "cat_idx = 0\n",
        "dog_idx = 0\n",
        "\n",
        "\n",
        "# was 2000\n",
        "while i < 2000:\n",
        "    if i % 2 == 0:\n",
        "        im = Image.open(os.path.join(cats_dir, cats_files[cat_idx])).convert(\"RGB\")\n",
        "        im_resized = im.resize(target_size)  # Resize the image\n",
        "        x_train.append(np.array(im_resized))\n",
        "        y_train.append(1)\n",
        "        cat_idx += 1\n",
        "    else:\n",
        "        im = Image.open(os.path.join(dogs_dir, dogs_files[dog_idx])).convert(\"RGB\")\n",
        "        im_resized = im.resize(target_size)  # Resize the image\n",
        "        x_train.append(np.array(im_resized))\n",
        "        y_train.append(0)\n",
        "        dog_idx += 1\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ahb3lzdJ1pLR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3),\n",
        "    pooling='avg',\n",
        "    classes=2,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAnkoVPe748_"
      },
      "outputs": [],
      "source": [
        "# Correct the path definitions\n",
        "\n",
        "\n",
        "# Continue with the rest of the code\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Define transformations for the dataset\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(150),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(150),\n",
        "        transforms.CenterCrop(150),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ImageFolder(train_dir, transform=data_transforms['train'])\n",
        "val_dataset = ImageFolder(validation_dir, transform=data_transforms['val'])\n",
        "\n",
        "# Create data loaders\n",
        "# Batch size was 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load the pretrained ResNet50 model\n",
        "pretrained_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the model\n",
        "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, 1)\n",
        "model = pretrained_model\n",
        "\n",
        "# Use binary cross entropy loss and Adam optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# num_epochs = 10\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "# Convert predictions to binary labels\n",
        "predictions = (np.array(all_preds) > 0.5).astype(int)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TM7jznYe_cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}